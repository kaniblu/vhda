type: hda
vargs:
  word_dim: 400
  sent_dim: 500
  asv_dim: 400
  state_dim: 500
  goal_dim: 500
  spkr_dim: 8
  conv_dim: 1000
  ctx_dim: 1000
  spkr_dropout: 0.0
  asv_dropout: 0.0
  goal_dropout: 0.0
  state_dropout: 0.0
  sent_dropout: 0.0
  word_dropout: 0.0
  word_encoder:
    type: composite
    vargs:
      first_dim: 300
      second_dim: 100
      first:
        type: vzhong-embeddings
        vargs:
          freeze: true
          cls_name: GloveEmbedding
          default: zero
      second:
        type: vzhong-embeddings
        vargs:
          freeze: true
          cls_name: KazumaCharEmbedding
          default: zero
  seq_encoder:
    type: self-attentional-rnn
    vargs:
      rnn:
        type: lstm
        vargs:
          dropout: 0
          layers: 1
          pack: true
  sent_decoder:
    type: rnn
    vargs:
      rnn_dim: 400
      decoding_rnn:
        type: lstm
        vargs:
          dropout: 0.0
          num_layers: 1
  state_decoder:
    type: generic
    vargs:
      hidden_dim: 400
  ctx_encoder:
    type: lstm
    vargs:
      dropout: 0.0
      num_layers: 1
